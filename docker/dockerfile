FROM python:3.11.5

# Update package list and install necessary packages
RUN apt-get update
RUN apt-get install sudo
RUN sudo apt-get install -y curl
RUN sudo apt-get install -y tesseract-ocr
RUN sudo apt-get install -y poppler-utils
RUN sudo apt-get install -y ffmpeg libsm6 libxext6  -y

# Install ollama (assuming it's available in the package repository)
RUN curl -fsSL https://ollama.com/install.sh | sh

# Ollama Serve + Pull Models
RUN ollama serve & sleep 5 && ollama pull phi3.5 && ollama pull nomic-embed-text && ollama pull llava-phi3

# pip install
COPY requirements.txt .
RUN pip install -r requirements.txt

# Set the working directory (you need to specify a directory) + Make if not exist
WORKDIR /LLM

# Copy Local Dirs into Container
COPY ./to_docker .

# Need to incorporate running the 2 files once to pull any models needed (but need figure out GPU, or only pull dont run)
# RUN python PULL_MODEL_SCRIPT.py

# Default command (optional, but useful for debugging)
CMD ["bash", "ollama serve > /dev/null 2>&1"]